{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What We will Learn\n",
    "\n",
    "1. S3 Buckets- Boto3\n",
    "2. Iam Roles and Users\n",
    "3. Complete Infrastructure of AWS Sagemaker-Training, Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sklearn.model_selection import train_test_split\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "sm_boto3=boto3.client(\"sagemaker\")\n",
    "sess=sagemaker.Session()\n",
    "region=sess.boto_session.region_name\n",
    "bucket=\"jailer8\"\n",
    "print(\"Using bucket\" + bucket)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"mob_price_classification_train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price_range'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price_range'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price_range'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=list(df.columns)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = features.pop(-1)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df[features]\n",
    "y=df[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = pd.DataFrame(X_train)\n",
    "trainX[label] = y_train\n",
    "\n",
    "testX = pd.DataFrame(X_test)\n",
    "testX[label] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.to_csv(\"train-V-1.csv\",index = False)\n",
    "testX.to_csv(\"test-V-1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## send data to S3. Sagemaker will take the data for training from s3\n",
    "sk_prefix=\"sagemaker/mobile_price_classification/sklearncontainer\"\n",
    "trainpath=sess.upload_data(path='train-V-1.csv',bucket=bucket,key_prefix=sk_prefix)\n",
    "\n",
    "testpath=sess.upload_data(path='test-V-1.csv',bucket=bucket,key_prefix=sk_prefix)\n",
    "\n",
    "print(trainpath)\n",
    "print(testpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "session = boto3.Session()\n",
    "creds = session.get_credentials()\n",
    "print(creds.access_key)\n",
    "print(creds.secret_key)\n",
    "print(creds.token)  # This should be None unless using temporary credentials\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Script used by AWS Sagemaker To Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile script.py\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn\n",
    "import joblib\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return clf\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\"--n_estimators\", type=int, default=100)\n",
    "    parser.add_argument(\"--max_depth\", type=int, default=None)\n",
    "    parser.add_argument(\"--random_state\", type=int, default=0)\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--train-file\", type=str, default=\"train-V-1.csv\")\n",
    "    parser.add_argument(\"--test-file\", type=str, default=\"test-V-1.csv\")\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    print(\"SKLearn Version:\", sklearn.__version__)\n",
    "    print(\"Joblib Version:\", joblib.__version__)\n",
    "\n",
    "    print(\"[INFO] Reading data\")\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "\n",
    "    features = list(train_df.columns)\n",
    "    label = features.pop(-1)\n",
    "\n",
    "    X_train = train_df[features]\n",
    "    y_train = train_df[label]\n",
    "    X_test = test_df[features]\n",
    "    y_test = test_df[label]\n",
    "\n",
    "    print(\"Training RandomForest Model with Cross-Validation...\")\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=args.n_estimators,\n",
    "        max_depth=args.max_depth,\n",
    "        random_state=args.random_state,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Perform 5-fold cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    print(\"Cross-validation scores:\", cv_scores)\n",
    "    print(\"Mean CV accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "    # Train the model on the full training set\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    model_path = os.path.join(args.model_dir, \"model.joblib\")\n",
    "    joblib.dump(model, model_path)\n",
    "    print(\"Model saved at\", model_path)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, y_pred_test)\n",
    "    test_rep = classification_report(y_test, y_pred_test)\n",
    "\n",
    "    print(\"\\n---- METRICS RESULTS FOR TESTING DATA ----\")\n",
    "    print(\"Total Rows:\", X_test.shape[0])\n",
    "    print('[TESTING] Model Accuracy:', test_acc)\n",
    "    print('[TESTING] Testing Report:')\n",
    "    print(test_rep)\n",
    "\n",
    "    # Save the mean CV score to a file that SageMaker can read\n",
    "    with open(os.path.join(args.model_dir, 'cv_accuracy.txt'), 'w') as f:\n",
    "        f.write(str(np.mean(cv_scores)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS Sagemaker Entry Point To Execute the Training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.tuner import IntegerParameter, HyperparameterTuner\n",
    "\n",
    "FRAMEWORK_VERSION = \"0.23-1\"\n",
    "\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point=\"script.py\",\n",
    "    role=\"arn:aws:iam::054037137868:role/sagemakeraccess\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    "    base_job_name=\"RF-custom-sklearn-cv\",\n",
    "    hyperparameters={\n",
    "        \"random_state\": 0\n",
    "    },\n",
    "    use_spot_instances=True,\n",
    "    max_run=3600\n",
    ")\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    'n_estimators': IntegerParameter(50, 150),\n",
    "    'max_depth': IntegerParameter(3, 15)\n",
    "}\n",
    "\n",
    "objective_metric_name = 'cv:accuracy'\n",
    "objective_type = 'Maximize'\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    sklearn_estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    max_jobs=20,\n",
    "    max_parallel_jobs=3,\n",
    "    objective_type=objective_type\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Launch training job\n",
    "tuner.fit({\"train\": trainpath, \"test\": testpath}, wait=True)\n",
    "\n",
    "# After tuning completes\n",
    "best_training_job = tuner.best_training_job()\n",
    "best_model = tuner.attach_to_best_training_job()\n",
    "\n",
    "print(f\"Best training job: {best_training_job}\")\n",
    "print(f\"Best hyperparameters: {best_model.hyperparameters()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To get the model from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_estimator.latest_training_job.wait(logs=\"None\")\n",
    "artifact = sm_boto3.describe_training_job(\n",
    "    TrainingJobName=sklearn_estimator.latest_training_job.name\n",
    ")[\"ModelArtifacts\"][\"S3ModelArtifacts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the Model For Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from time import gmtime,strftime\n",
    "\n",
    "\n",
    "model_name=\"Custom-sklearn-model-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "model=SKLearnModel(\n",
    "    name=model_name,\n",
    "    model_data=artifact,\n",
    "    role=\"arn:aws:iam::054037137868:role/sagemakeraccess\",\n",
    "    entry_point=\"script.py\",\n",
    "    framework_version=FRAMEWORK_VERSION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Endpoint deployment\n",
    "endpoint_name=\"Custom-sklearn-model-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"EndpointName={}\".format(endpoint_name))\n",
    "\n",
    "predictor=model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    endpoint_name=endpoint_name\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX[features][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictor.predict(testX[features][:2].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_boto3.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
